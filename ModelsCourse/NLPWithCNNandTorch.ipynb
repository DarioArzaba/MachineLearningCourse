{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NLP.ipynb","provenance":[{"file_id":"1eS-JW9QlpMOa7d5w63mh05yCsMsDjTuJ","timestamp":1631158708240}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# NLP CNN\n","\n","Este es el codigo para entregar una CNN para analisis de sentimiento del texto.\n"],"metadata":{"id":"Tx5WFXv-oFnh"}},{"cell_type":"markdown","source":["## 1.1 Instalacion\n","\n","Los siguientes paquetes son necesario para la ejecucion"],"metadata":{"id":"WUNxqS7nogLN"}},{"cell_type":"markdown","source":["Para instalar localmente seguir https://pytorch.org/get-started/locally/: "],"metadata":{"id":"2wpSjYJYDbfM"}},{"cell_type":"code","source":["#pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cpu"],"metadata":{"id":"N0poYgfvDgCx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install -U torch==1.8.0 torchtext==0.9.0 --quiet\n","!python -m spacy download en_core_web_sm --quiet\n","\n","# Reload environment\n","exit()"],"metadata":{"id":"uBLE_wACpiwC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652456843153,"user_tz":300,"elapsed":107118,"user":{"displayName":"Marcial Roberto Leyva Fernández","userId":"17265902431038122546"}},"outputId":"bc981f04-ec3e-45aa-bd17-8b08f4d4ebb6"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 735.5 MB 14 kB/s \n","\u001b[K     |████████████████████████████████| 7.1 MB 63.1 MB/s \n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.12.0+cu113 requires torch==1.11.0, but you have torch 1.8.0 which is incompatible.\n","torchaudio 0.11.0+cu113 requires torch==1.11.0, but you have torch 1.8.0 which is incompatible.\u001b[0m\n","\u001b[?25hCollecting en_core_web_sm==2.2.5\n","  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz (12.0 MB)\n","\u001b[K     |████████████████████████████████| 12.0 MB 22.0 MB/s \n","\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n","Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.7)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (57.4.0)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.6)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.6)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.21.6)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.64.0)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.9.1)\n","Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.11.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.8.0)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.2.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the model via spacy.load('en_core_web_sm')\n"]}]},{"cell_type":"markdown","source":["Este es el archivo donde se encuentra la CNN"],"metadata":{"id":"Cas3wT70G1gG"}},{"cell_type":"code","source":["!gdown https://drive.google.com/uc?id=1gWADou0gg3qBx_IncP4zBHV6TZWDezFi --quiet\n","\n","!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5O45WqxeGp-l","executionInfo":{"status":"ok","timestamp":1652456965365,"user_tz":300,"elapsed":997,"user":{"displayName":"Marcial Roberto Leyva Fernández","userId":"17265902431038122546"}},"outputId":"a6c926ee-5e84-4b3a-a9a6-5f930b7aff04"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["CNN_model.py  sample_data\n"]}]},{"cell_type":"markdown","source":["## 1.2 Carga de paquetes\n","\n","Esta es la carga de la paqueteria necesaria"],"metadata":{"id":"6alUZGTdokdU"}},{"cell_type":"code","source":["import torch\n","from torchtext.legacy import data\n","from torchtext.legacy import datasets\n","import time, random\n","from CNN_model import CNN\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from datetime import datetime"],"metadata":{"id":"pecSWmE0pZMo","executionInfo":{"status":"ok","timestamp":1652457508850,"user_tz":300,"elapsed":261,"user":{"displayName":"Marcial Roberto Leyva Fernández","userId":"17265902431038122546"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["SEED = 1234\n","\n","torch.manual_seed(SEED)\n","torch.cuda.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True\n","\n","print('Training vocabulary for tokeniser ...')\n","\n","TEXT = data.Field(tokenize='spacy')\n","LABEL = data.LabelField(dtype=torch.float)\n","\n","train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)\n","\n","train_data, valid_data = train_data.split(random_state=random.seed(SEED))\n","\n","TEXT.build_vocab(train_data, max_size=25000, vectors=\"glove.6B.100d\")\n","LABEL.build_vocab(train_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CcLSmx6qqHfk","executionInfo":{"status":"ok","timestamp":1652457610021,"user_tz":300,"elapsed":98104,"user":{"displayName":"Marcial Roberto Leyva Fernández","userId":"17265902431038122546"}},"outputId":"4bd1787a-b71b-4e80-c99d-b69a2bc4f395"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Training vocabulary for tokeniser ...\n"]}]},{"cell_type":"code","source":["print('[end]')\n","\n","BATCH_SIZE = 64\n","\n","device = torch.device('cpu')\n","\n","train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n","    (train_data, valid_data, test_data), \n","    batch_size=BATCH_SIZE, \n","    device=device)\n","\n","INPUT_DIM = len(TEXT.vocab)\n","EMBEDDING_DIM = 100\n","N_FILTERS = 100\n","FILTER_SIZES = [3,4,5]\n","#N_FILTERS = 200\n","#FILTER_SIZES = [3,5,7] # works better\n","OUTPUT_DIM = 1\n","DROPOUT = 0.5\n","\n","model = CNN(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT)\n","\n","pretrained_embeddings = TEXT.vocab.vectors\n","\n","model.embedding.weight.data.copy_(pretrained_embeddings)\n","\n","import torch.optim as optim\n","\n","optimizer = optim.Adam(model.parameters())\n","\n","criterion = nn.BCEWithLogitsLoss()\n","\n","model = model.to(device)\n","criterion = criterion.to(device)\n","\n","def binary_accuracy(preds, y):\n","    \"\"\"\n","    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n","    \"\"\"\n","    #round predictions to the closest integer\n","    rounded_preds = torch.round(torch.sigmoid(preds))\n","    correct = (rounded_preds == y).float() #convert into float for division \n","    acc = correct.sum()/len(correct)\n","    return acc\n","\n","def train(model, iterator, optimizer, criterion):\n","    epoch_loss = 0\n","    epoch_acc = 0\n","    model.train()\n","    for batch in iterator:\n","        optimizer.zero_grad()\n","        #predictions = model(batch.text).squeeze(1)\n","        predictions , __ = model(batch.text)\n","        predictions = predictions.squeeze(1)\n","        loss = criterion(predictions, batch.label)\n","        acc = binary_accuracy(predictions, batch.label)\n","        loss.backward()\n","        optimizer.step()\n","        epoch_loss += loss.item()\n","        epoch_acc += acc.item()\n","    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n","\n","def evaluate(model, iterator, criterion):\n","    \n","    epoch_loss = 0\n","    epoch_acc = 0\n","    model.eval()\n","    \n","    with torch.no_grad():\n","    \n","        for batch in iterator:\n","\t\t        #predictions = model(batch.text).squeeze(1)\n","            predictions, __ = model(batch.text)\n","            predictions = predictions.squeeze(1)\n","            loss = criterion(predictions, batch.label)\n","            acc = binary_accuracy(predictions, batch.label)\n","            epoch_loss += loss.item()\n","            epoch_acc += acc.item()\n","    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n","\n","N_EPOCHS = 5 # more >> overfitting"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YYohlXTArfQu","executionInfo":{"status":"ok","timestamp":1652457655910,"user_tz":300,"elapsed":171,"user":{"displayName":"Marcial Roberto Leyva Fernández","userId":"17265902431038122546"}},"outputId":"e2fb64f1-9ab7-49b0-ee6e-cf66f5833587"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["[end]\n"]}]},{"cell_type":"code","source":["for epoch in range(N_EPOCHS):\n","\n","    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n","    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n","    \n","    print(f'| Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% | Val. Loss: {valid_loss:.3f} | Val. Acc: {valid_acc*100:.2f}% |')\n","\n","test_loss, test_acc = evaluate(model, test_iterator, criterion)\n","\n","print(f'| Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}% |')\n","\n","mFile = datetime.now().strftime('%Y-%m-%d-%H-%M-%S');\n","\n","print('Saving model ...')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":416},"id":"2FibdOk5riMt","executionInfo":{"status":"error","timestamp":1652459002388,"user_tz":300,"elapsed":1341864,"user":{"displayName":"Marcial Roberto Leyva Fernández","userId":"17265902431038122546"}},"outputId":"fe43d709-13bd-4af4-faa6-e05414b66170"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["| Epoch: 01 | Train Loss: 0.500 | Train Acc: 74.16% | Val. Loss: 0.344 | Val. Acc: 85.31% |\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-a6240006e1ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-11-110ff9d506ca>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbinary_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["input('Enter comments: ')"],"metadata":{"id":"e1aMe9rAD8-V"},"execution_count":null,"outputs":[]}]}