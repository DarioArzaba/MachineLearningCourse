{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NLP.ipynb","provenance":[{"file_id":"1eS-JW9QlpMOa7d5w63mh05yCsMsDjTuJ","timestamp":1631158708240}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"code","source":["!pip install -U torch==1.8.0 torchtext==0.9.0 --quiet\n","\n","# Reload environment\n","exit()"],"metadata":{"id":"uBLE_wACpiwC","executionInfo":{"status":"ok","timestamp":1650980432442,"user_tz":300,"elapsed":5098,"user":{"displayName":"Marcial Roberto Leyva Fernández","userId":"17265902431038122546"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["import torch\n","from torchtext.legacy import data\n","from torchtext.legacy import datasets\n","import time, random\n","from CNN_model import CNN\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from datetime import datetime"],"metadata":{"id":"pecSWmE0pZMo","executionInfo":{"status":"ok","timestamp":1650980457561,"user_tz":300,"elapsed":125,"user":{"displayName":"Marcial Roberto Leyva Fernández","userId":"17265902431038122546"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["SEED = 1234\n","\n","torch.manual_seed(SEED)\n","torch.cuda.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True\n","\n","print('Training vocabulary for tokeniser ...')\n","\n","TEXT = data.Field(tokenize='spacy')\n","LABEL = data.LabelField(dtype=torch.float)\n","\n","train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)\n","\n","train_data, valid_data = train_data.split(random_state=random.seed(SEED))\n","\n","TEXT.build_vocab(train_data, max_size=25000, vectors=\"glove.6B.100d\")\n","LABEL.build_vocab(train_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CcLSmx6qqHfk","executionInfo":{"status":"ok","timestamp":1650980813722,"user_tz":300,"elapsed":352958,"user":{"displayName":"Marcial Roberto Leyva Fernández","userId":"17265902431038122546"}},"outputId":"8ecfbaa1-3fd4-4dad-f38c-251d4f58a5cc"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Training vocabulary for tokeniser ...\n","downloading aclImdb_v1.tar.gz\n"]},{"output_type":"stream","name":"stderr","text":["aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:03<00:00, 22.8MB/s]\n",".vector_cache/glove.6B.zip: 862MB [02:42, 5.30MB/s]                           \n","100%|█████████▉| 399999/400000 [00:19<00:00, 20625.07it/s]\n"]}]},{"cell_type":"code","source":["print('[end]')\n","\n","BATCH_SIZE = 64\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n","    (train_data, valid_data, test_data), \n","    batch_size=BATCH_SIZE, \n","    device=device)\n","\n","INPUT_DIM = len(TEXT.vocab)\n","EMBEDDING_DIM = 100\n","N_FILTERS = 100\n","FILTER_SIZES = [3,4,5]\n","#N_FILTERS = 200\n","#FILTER_SIZES = [3,5,7] # works better\n","OUTPUT_DIM = 1\n","DROPOUT = 0.5\n","\n","model = CNN(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT)\n","\n","pretrained_embeddings = TEXT.vocab.vectors\n","\n","model.embedding.weight.data.copy_(pretrained_embeddings)\n","\n","import torch.optim as optim\n","\n","optimizer = optim.Adam(model.parameters())\n","\n","criterion = nn.BCEWithLogitsLoss()\n","\n","model = model.to(device)\n","criterion = criterion.to(device)\n","\n","def binary_accuracy(preds, y):\n","    \"\"\"\n","    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n","    \"\"\"\n","    #round predictions to the closest integer\n","    rounded_preds = torch.round(torch.sigmoid(preds))\n","    correct = (rounded_preds == y).float() #convert into float for division \n","    acc = correct.sum()/len(correct)\n","    return acc\n","\n","def train(model, iterator, optimizer, criterion):\n","    epoch_loss = 0\n","    epoch_acc = 0\n","    model.train()\n","    for batch in iterator:\n","        optimizer.zero_grad()\n","        #predictions = model(batch.text).squeeze(1)\n","        predictions , __ = model(batch.text)\n","        predictions = predictions.squeeze(1)\n","        loss = criterion(predictions, batch.label)\n","        acc = binary_accuracy(predictions, batch.label)\n","        loss.backward()\n","        optimizer.step()\n","        epoch_loss += loss.item()\n","        epoch_acc += acc.item()\n","    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n","\n","def evaluate(model, iterator, criterion):\n","    \n","    epoch_loss = 0\n","    epoch_acc = 0\n","    model.eval()\n","    \n","    with torch.no_grad():\n","    \n","        for batch in iterator:\n","\t\t        #predictions = model(batch.text).squeeze(1)\n","            predictions, __ = model(batch.text)\n","            predictions = predictions.squeeze(1)\n","            loss = criterion(predictions, batch.label)\n","            acc = binary_accuracy(predictions, batch.label)\n","            epoch_loss += loss.item()\n","            epoch_acc += acc.item()\n","    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n","\n","N_EPOCHS = 5 # more >> overfitting"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YYohlXTArfQu","executionInfo":{"status":"ok","timestamp":1650980938871,"user_tz":300,"elapsed":614,"user":{"displayName":"Marcial Roberto Leyva Fernández","userId":"17265902431038122546"}},"outputId":"7326faac-b110-4e97-c5cd-ab7e213587fa"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["[end]\n"]}]},{"cell_type":"code","source":["for epoch in range(N_EPOCHS):\n","\n","    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n","    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n","    \n","    print(f'| Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% | Val. Loss: {valid_loss:.3f} | Val. Acc: {valid_acc*100:.2f}% |')\n","\n","test_loss, test_acc = evaluate(model, test_iterator, criterion)\n","\n","print(f'| Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}% |')\n","\n","mFile = datetime.now().strftime('%Y-%m-%d-%H-%M-%S');\n","\n","print('Saving model ...')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":451},"id":"2FibdOk5riMt","executionInfo":{"status":"error","timestamp":1650985250990,"user_tz":300,"elapsed":4309455,"user":{"displayName":"Marcial Roberto Leyva Fernández","userId":"17265902431038122546"}},"outputId":"4f41c762-1cda-47e7-8f71-1bdae036fc73"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["| Epoch: 01 | Train Loss: 0.500 | Train Acc: 74.23% | Val. Loss: 0.346 | Val. Acc: 85.37% |\n","| Epoch: 02 | Train Loss: 0.304 | Train Acc: 87.33% | Val. Loss: 0.297 | Val. Acc: 87.39% |\n","| Epoch: 03 | Train Loss: 0.217 | Train Acc: 91.58% | Val. Loss: 0.278 | Val. Acc: 88.59% |\n","| Epoch: 04 | Train Loss: 0.149 | Train Acc: 94.74% | Val. Loss: 0.278 | Val. Acc: 89.12% |\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-a6240006e1ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-3f3693dcb6bd>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbinary_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}